Criteria = c("Exact match on all fields: surname, givname, midname, sex, and birthdate",
"Missing midname and match all other fields",
"Match partial midname and match all other fields",
"Not exact match midname and match all other fields",
"Match surname, givname, midname, sex, birthyear and
a) match birthmon and one day/two days of birthday difference, or
b) match birthday and one month of birthmon difference",
"Match surname, givname, midname, birthyear and
ido_birthmon = lcf_birthday and lcf_birthmon = ido_birthday",
"Match surname, givname, sex, birthyear and a) / b) and missing midname
a) match birthmon and one day/two days of birthday difference
b) match birthday and one month of birthmon difference",
"Match surname, givname, midname, sex, birthmon, birthday and one year of birthyear difference",
"Match surname, givname, midname, birthdate and missing sex / not match sex",
"Match surname, sex, birthdate and match partial givname and partial midname",
"Match surname, midname, sex, birthyear, birthmon, partial givname and match a) / b) / c)
a) match birthday,
b) one day of birthday difference
c) two days of birthday difference",
"Match surname, sex, birthyear, birthmon, partial givname and match a) / b) / c) and missing midname
a) match birthday
b) one day of birthday difference
c) two days of birthday difference",
"Match surname, sex, birthyear, birthmon, ido_givname = lcf_midname, lcf_givname = ido_midname
and a) / b)
a) match birthday
b) one day of birthday difference",
"Inspect cases with a) / b)  / c)
a) match surname, givname, sex, birthyear, birthmon and one day/two days of birthday difference
b) match surname, partial givname, partial midname, sex, birthyear, birthmon and
one day / two day of birthday difference
c) match partial surname, partial givname, partial midname, sex, birthyear, birthmon and
one day / two day of birthday difference",
"Match givname, midname/partial midname, birthdate, sex = F and different surname",
"6 out of 7 matches",
"Linked records",
"Unlinked records",
"Total records"),
Count = c(108035, 23160, 5832, 290, 567, 144, 175, 245, 175, 3687, 182, 144, 453, 1106, 284, 956, 145435, 6714, 152149),
Percent = c(71.01, 15.22, 3.83, 0.19, 0.37, 0.09, 0.12, 0.16, 0.12, 2.42, 0.12, 0.09, 0.30, 0.73, 0.19, 0.63, 95.59, 4.41, 100.00), stringsAsFactors = FALSE)
print(kable(PSSG))
kable(PSSG)
kable(PSSG)
knitr::opts_chunk$set(echo = TRUE)
getwd() # Shows the working directory (wd)
setwd(choose.dir()) # Select the working directory interactively
getwd() # Shows the working directory (wd)
setwd(choose.dir(x)) # Select the working directory interactively
getwd() # Shows the working directory (wd)
setwd(choose.dir()) # Select the working directory interactively
getwd() # Shows the working directory (wd)
setwd(choose.dir(/Users/nnabavi/Data_Science_Practices)) # Select the working directory interactively
getwd() # Shows the working directory (wd)
setwd(choose.dir(Users/nnabavi/Data_Science_Practices)) # Select the working directory interactively
library(knitr)
library(kableExtra)
Education <- data.frame(
id = 1:7,
University = c("University of British Columbia",
"University of British Columbia",
"University of British Columbia",
"University of California, San Francisco",
"University of California, Berkeley",
"University of Toronto",
"University of Toronto"),
Program = c("Centre for Integrated Teaching and Learning",
"Graduate Management Consulting Association",
"Urologic Sciences",
"Cellular and Molecular Pharmacology",
"Metabolic Biology and Nutritional Toxicology",
"Cell and Systems Biology",
"Cell and Molecular Biology"),
Degree = c("Teaching and Learning Associate Diploma",
"Mini-MBA Diploma - Instructors: Drs. Ray Socha, Kat Rothe",
"Post Doctoral Fellowship - Advisors: Profs. Colin Collins, Yuzhuo Wang",
"Post Doctoral Fellowship - Advisor: Prof. Maria Almira Correia",
"Post Doctoral Fellowship - Advisor: Prof. Danica Chen",
"Ph.D. Degree - Advisor: Prof. Rene Harrison",
"B.Sc. Degree - Honors, Co-op distinction"),
Dates = c("2018",
"2018",
"2015-2018",
"2013-2014",
"2012-2013",
"2005-2012",
"2001-2005"),
stringsAsFactors = FALSE)
kable(Education) %>%
kable_styling(bootstrap_options = c("striped", "hover", full_width = F))
library(kableExtra)
library(kableExtra)
library(knitr)
library(kableExtra)
Family <- data.frame(
# = 1:26,
Table_ID = c("Table I-01", "Table I-02", "Table I-3A", "Table I-3B", "Table I-3C", "Table I-04A", "Table I-04B", "Table I-04C", "Table I-5A", "Table I-5B", "Table I-06", "Table I-7", "Table I-08", "Table I-09", "Table I-10", "Table I-11", "Table I-12", "Table I-13", "Table I-14A", "Table I-14B", "Table I-14C", "Table I-15", "Table I-17", "Table I-18", "Table I-19", "Table I-20"),
Table_Name = c("Summary census family income table", "Taxfilers and dependents by age groups and census family type", "Couple families by age of older partner or parent and number of children", "Lone-Parent families by age of parent and number of children", "Census families by age of older partner or parent and number of children", "Distribution of total income by couple family and age of older partner or parent", "Distribution of total income by lone-parent family and age of parent", "Distribution of total income of persons not in census families by age of individual", "Couple families by total income and number of children", "Lone-Parent families by total income and number of children", "Sources of Income by census family Type", "Economic dependency profile of couple families", "Economic dependency profile of lone-parent families and persons not in census families", "Labour income profile of couple families", "Labour income profile of lone-parent families and persons not in census families", "Labour income by age group and sex", "Employment insurance by age group and sex", "Single-earner and dual-earner families by number of children, includes only partners, parents reporting non-negative employment income", "Couple families by percentage of wife's contribution to couple's employment income and by number of children", "Couple families by percentage of wife's contribution to husband/wife employment income and by age of wife", "Couple families by percentage of wife's contribution to husband, wife employment income and by family employment income range", "Census families with children by age of children and children by age groups", "Before-tax low income status, based on census family low income measures, family type and family composition", "After-tax low income status, based on census family low income measures, by family type and family composition", "After-tax low income status of census families, census family low income measures, by family type and family composition, adjusted methodology", "Census families by family type and family composition including before and after-tax median income of the family"),
stringsAsFactors = FALSE)
library(knitr)
library(kableExtra)
Family <- data.frame(
# = 1:26,
Table_ID = c("Table I-01", "Table I-02", "Table I-3A", "Table I-3B", "Table I-3C", "Table I-04A", "Table I-04B", "Table I-04C", "Table I-5A", "Table I-5B", "Table I-06", "Table I-7", "Table I-08", "Table I-09", "Table I-10", "Table I-11", "Table I-12", "Table I-13", "Table I-14A", "Table I-14B", "Table I-14C", "Table I-15", "Table I-17", "Table I-18", "Table I-19", "Table I-20"),
Table_Name = c("Summary census family income table", "Taxfilers and dependents by age groups and census family type", "Couple families by age of older partner or parent and number of children", "Lone-Parent families by age of parent and number of children", "Census families by age of older partner or parent and number of children", "Distribution of total income by couple family and age of older partner or parent", "Distribution of total income by lone-parent family and age of parent", "Distribution of total income of persons not in census families by age of individual", "Couple families by total income and number of children", "Lone-Parent families by total income and number of children", "Sources of Income by census family Type", "Economic dependency profile of couple families", "Economic dependency profile of lone-parent families and persons not in census families", "Labour income profile of couple families", "Labour income profile of lone-parent families and persons not in census families", "Labour income by age group and sex", "Employment insurance by age group and sex", "Single-earner and dual-earner families by number of children, includes only partners, parents reporting non-negative employment income", "Couple families by percentage of wife's contribution to couple's employment income and by number of children", "Couple families by percentage of wife's contribution to husband/wife employment income and by age of wife", "Couple families by percentage of wife's contribution to husband, wife employment income and by family employment income range", "Census families with children by age of children and children by age groups", "Before-tax low income status, based on census family low income measures, family type and family composition", "After-tax low income status, based on census family low income measures, by family type and family composition", "After-tax low income status of census families, census family low income measures, by family type and family composition, adjusted methodology", "Census families by family type and family composition including before and after-tax median income of the family"),
stringsAsFactors = FALSE)
View(Family)
list.files(dir.wrk)
setwd("~/Desktop/IncomeData_STATSCan/R-Codes")
getwd()
dir.wrk <- "~/Desktop/IncomeData_STATSCan/R-Codes"
dir.wrk <- getwd()
list.files(dir.wrk)
setwd("~/Desktop/IncomeData_STATSCan/R-Codes")
getwd()
dir.wrk <- "~/Desktop/IncomeData_STATSCan/R-Codes"
dir.wrk <- getwd()
nrow(installed.packages())
library(bcgovr)
library(bcdata)
library(bcgovr)
detach("package:bcdata", unload=TRUE)
library(here)
here
here()
create_bcgov_project(path = ""/Users/nnabavi"", rmarkdown = TRUE,
licence = "apache2", coc_email = get_coc_email(),
dir_struct = getOption("bcgovr.dir.struct", default = NULL),
rstudio = rstudioapi::isAvailable(), open = TRUE)
create_bcgov_project(path = "/Users/nnabavi", rmarkdown = TRUE,
licence = "apache2", coc_email = get_coc_email(),
dir_struct = getOption("bcgovr.dir.struct", default = NULL),
rstudio = rstudioapi::isAvailable(), open = TRUE)
create_bcgov_project(path = "/Users/nnabavi", rmarkdown = TRUE,
licence = "apache2", coc_email = get_coc_email(noushin.nabavi@gov.bc.ca),
dir_struct = getOption("bcgovr.dir.struct", default = NULL),
rstudio = rstudioapi::isAvailable(), open = TRUE)
bcgovr::create_bcgov_project()
library(reprex)
reprex()
library(bcgovr)
sessionInfo()
library(reprex)
reprex()
library(usethis)
library(bcgovr)
library(reprex)
sessionInfo()
reprex()
bcgovr::create_bcgov_package()
bcgovr::create_bcgov_project()
bcgovr::create_bcgov_project("bc-econ-status-indices")
# xts and zoo objects
# Load xts library
library(xts)
# View the structure of ex_matrix
str(ex_matrix)
# xts objects are simple. Think of them as a matrix of observations combined with an index of corresponding dates and times.
# Create the object data using 5 random numbers
data <- rnorm(5)
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")
smith <- xts(x = data, order.by = dates)
smith <- xts(x = data, order.by = dates)
bday <- as.POSIXct("1899-05-08")
hayek <- xts(x = data, order.by = dates, born = bday)
View(smith)
smith <- xts(x = data, order.by = dates)
smiths
smith
print(some_data)
# xts objects are simple. Think of them as a matrix of observations combined with an index of corresponding dates and times.
# Create the object data using 5 random numbers
data <- rnorm(5)
print(data)
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")
data_dates <- xts(x = data, order.by = dates)
print(data_dates)
bday
one_date <- as.POSIXct("1899-05-08")
hayek
some_dates <- xts(x = data, order.by = dates, born = one_date)
print(some_dates)
print(one_date)
some_dates_core <- coredata(some_dates)
print(some_dates_core)
# View the class of some_dates_core
class(some_dates_core)
some_dates_core_index <- index(some_dates_core)
# View the class of hayek_index
class(some_dates_core_index)
dates <- as.Date("2016-01-01") + 0:4
# Create ts_a
ts_a <- xts(x = 1:5, order.by = dates)
# Create ts_b
ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))
# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_b)]
# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]
# Importing, exporting and converting time series
data(sunspots)
au <- as.xts(austres)
am <- as.matrix(au)
head(am)
austres
data(austres)
au <- as.xts(austres)
print(au)
print(am)
# Inspect the head of am
head(am)
head(au)
am2 <- as.matrix(austres)
head(am2)
class(au)
class(am)
dat <- read.csv(tmp_file)
head(sunspots)
sunspots
temp_url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
temp_url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
dat <- read.csv(temp_url)
View(dat)
head(dat)
head(dat)
xts(dat, order.by = as.Date(rownames(dat), "%m/%d/%Y"))
dat_zoo <- read.zoo(tmp_file, index.column = 0, sep = ",", format = "%m/%d/%Y")
library(zoo)
dat_zoo <- read.zoo(tmp_file, index.column = 0, sep = ",", format = "%m/%d/%Y")
dat_zoo <- read.zoo(temp_url, index.column = 0, sep = ",", format = "%m/%d/%Y")
dat_xts <- as.xts(dat_zoo)
head(dat_xts)
sunspots_xts <- as.xts(sunspots)
tmp <- tempfile()
write.zoo(sunspots_xts, sep = ",", file = tmp)
sun <- read.zoo(tmp, sep = ",", FUN = as.yearmon)
sun_xts <- as.xts(sun)
tempfile()
head(sun)
# Convert sun into xts. Save this as sun_xts
sun_xts <- as.xts(sun)
head(sun_xts)
x_2016 <- x["2016"]
# Extracting recurring intraday intervals
# Intraday times for all days
# NYSE["T09:30/T16:00"]
# Extract all data between 8AM and 10AM
morn_2010 <- irreg["T08:00/T10:00"]
# Extract the observations for January 13th, 2010
morn_2010["2010-01-13"]
irreg
# Subset x using the vector dates
x[dates]
# Subset x using dates as POSIXct
x[as.POSIXct(dates)]
# time based queries
### A["20090825"]       ## Aug 25, 2009
### A["201203/201212"]  ## Mar to Dec 2012
### A["/201601"]        ## Up to and including January 2016
x <- fread("data_1.csv")
# time based queries
### A["20090825"]       ## Aug 25, 2009
### A["201203/201212"]  ## Mar to Dec 2012
### A["/201601"]        ## Up to and including January 2016
x <- readr::fread("data_1.csv")
library(here)
here
here()
setwd("~/STEM_Education/Data Analysis Lessons/8. DATA PREP")
path <- set_here("~/STEM_Education/Data Analysis Lessons/8. DATA PREP")
x <- readr::fread("data_1.csv")
x <- readr::fread(path, "data_1.csv")
x <- read.table::fread(path, "data_1.csv")
x <- data.table::fread(path, "data_1.csv")
x <- data.table::fread("data_1.csv")
x_2016 <- x["2016"]
# Select all of 2016 from x
x_2016 <- x["2010"]
x <- as.xts(x)
# Select all of 2016 from x
x_2016 <- x["2010"]
path <- set_here("~/STEM_Education/Data Analysis Lessons/8. DATA PREP")
x <- data.table::fread("data_1.csv")
x <- as.xts(x)
x <- as.xts(x)
x <- read.zoo(path, index.column = 0, sep = ",", format = "%m/%d/%Y")
x <- read.zoo("data_1.csv", index.column = 0, sep = ",", format = "%m/%d/%Y")
x <- fread("data_1.csv")
x <- data.table::fread("data_1.csv")
x
x[DATE] <- as.Date("DATE")
x[DATE] <- as.Date("Jul-01")
x[DATE] <- as.Date('1915-6-16')
x[DATE] <- as.Date('Jul-01',format='%m %Y, %d')
x[,DATE] <- as.Date('Jul-01',format='%m %Y, %d')
x$DATE
x$DATE <- as.Date('Jul-01',format='%m %Y, %d')
x[,"DATE"] <- as.Date('Jul-01',format='%m %Y, %d')
x[,1] <- as.Date('Jul-01',format='%m %Y, %d')
head(x)
x <- data.table::fread("data_1.csv")
head(x)
x[,1] <- as.Date('Jul-01',format='%m %Y, %d')
x <- data.table::fread("data_1.csv")
x[,"DATE"] <- as.Date('Jun-15',format = '%m %Y, %d')
class(x)
# Get the temporary file name
tmp <- tempfile()
head(sun_xts)
# Subset x using the vector dates
sun_xts[]
head(sun_xts)
# Subset x using dates as POSIXct
sun_xts[as.POSIXct(dates)]
# Subset x using dates as POSIXct
sun_xts[as.POSIXct()]
head(dat)
# Importing, exporting and converting time series
# It is often necessary to convert between classes when working with time series data in R.
data(sunspots)
sunspots
# Create ts_a
ts_a <- xts(x = 1:5, order.by = dates)
head(ts_a)
head(ts_b)
print(data_dates)
print(one_date)
print(some_dates)
dim(some_dates)
class(some_dates_core)
print(some_dates_core)
# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]
head(am2)
head(dat)
head(dat_xts)
temps
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")
print(dates)
AirPass
data(AirPass)
data(airpass)
install.packages("TSA")
library(TSA)
# NA interpolation using na.approx()
# Interpolate NAs using linear approximation
## Airpass data: install.packages("TSA") and library(TSA)
data("airpass")
airpass
head(airpass)
head("airpass")
head(AirPass)
head(airpass)
na.approx(airpass)
# Handling missingness in your data
# Fill missing values in temps using the last observation
temps_last <- na.locf(airpass)
print(temps_last)
print(temps_last)
temps_last <- na.locf(airpass)
print(temps_last)
temps_next <- na.locf(airpass, fromLast = TRUE)
head(temps_next)
print(temps_next)
na.approx(airpass)
lead_x <- lag(airpass, k = -1)
print(lead_x)
lag_x  <- lag(airpass, k = 1)
print(lag_x)
z <- merge(lead_x, x, lag_x)
# Create lastweek using the last 1 week of temps
lastmonth <- last(airpass, "1 month")
lastmonth <- last(airpass, "1 month")
diff_by_hand <- airpass - lag(airpass)
print(diff_by_hand)
merge(head(diff_by_hand), head(diff(airpass)))
diff(airpass, lag = 12, differences = 1)
lead_x <- lag(airpass, k = -1)
print(lead_x)
lag_x  <- lag(airpass, k = 1)
print(lag_x)
z <- merge(lead_x, x, lag_x)
diff_by_hand <- airpass - lag(airpass)
print(diff_by_hand)
merge(head(diff_by_hand), head(diff(airpass)))
diff(airpass, lag = 12, differences = 1)
temps_next <- na.locf(airpass, fromLast = TRUE)
print(temps_next)
endpoints(temps, on = "weeks")
endpoints(airpass, on = "years")
endpoints(temps, on = "months", k = 2)
endpoints(airpass, on = "years", k = 2)
## In order to find the end of the second year, you should set k = 2 in your second endpoints() call.
ep <- endpoints(airpass, on = "years")
ep <- endpoints(airpass, on = "years")
period.apply(ep[, "Temp.Mean"], INDEX = ep, FUN = mean)
period.apply(airpass[, "Temp.Mean"], INDEX = ep, FUN = mean)
ep
period.apply(airpass[, "Temp.Mean"], INDEX = ep, FUN = mean)
airpass
temps_weekly <- split(airpass, f = "years")
temps_avg <- lapply(X = temps_yearly, FUN = mean)
temps_yearly <- split(airpass, f = "years") # could also split by "months" etc.
temps_avg <- lapply(X = temps_yearly, FUN = mean)
temps_avg
temps_1 <- do.call(rbind, lapply(split(airpass, "years"), function(w) last(w, n = "1 day")))
last_day_of_weeks <- endpoints(airpass, "years")
last_year_of_data <- endpoints(airpass, "years")
print(last_year_of_data)
temps_2 <- airpass[last_year_of_data]
temps_2
temps_1 <- do.call(rbind, lapply(split(airpass, "years"), function(w) last(w, n = "1 year")))
temps_1 <- do.call(rbind, lapply(split(airpass, "years"), function(w) last(w, n = "1 day")))
airpass
temps_1 <- do.call(rbind, lapply(split(airpass, "weeks"), function(w) last(w, n = "1 day")))
temps_1 <- do.call(rbind, lapply(split(airpass, "years")))
temps_1 <- do.call(rbind, lapply(split(airpass, "years"), function(w) last(w)))
temps_1
usd_eur_weekly <- to.period(usd_eur, period = "weeks")
# Convert usd_eur to monthly and assign to usd_eur_monthly
usd_eur_monthly <- to.period(usd_eur, period = "months")
# Convert usd_eur to yearly univariate and assign to usd_eur_yearly
usd_eur_yearly <- to.period(usd_eur, period = "years", OHLC = FALSE)
x <- readxl::read_excel("data_1.csv", sheet = 1)
x <- readxl::read_excel("data_1.xls", sheet = 1)
x[,"DATE"] <- as.Date('Jun-15',format = '%m %Y, %d')
x <- as.xts(x)
x
usd_eur <- readxl::read_excel("data_1.xls", sheet = 2)
usd_eur <- readxl::read_excel("data_1.xls", sheet = 2)
usd_eur_weekly <- to.period(usd_eur, period = "weeks")
usd_eur_monthly <- to.period(usd_eur, period = "months")
usd_eur_yearly <- to.period(usd_eur, period = "years", OHLC = FALSE)
usd_eur <- readxl::read_excel("data_1.xls", sheet = 2)
usd_eur
usd_eur_weekly <- to.period(usd_eur, period = "weeks")
# Convert eq_mkt to quarterly OHLC
mkt_quarterly <- to.period(usd_eur, period = "quarters")
mkt_quarterly2 <- to.quarterly(usd_eur, name = "edhec_equity", indexAt = "firstof")
edhec <- readxl::read_excel("data_1.xls", sheet = 3)
# Split edhec into years
edhec_years <- split(edhec, f = "years")
# Use lapply to calculate the cumsum for each year in edhec_years
edhec_ytd <- lapply(edhec_years, FUN = cumsum)
# Use do.call to rbind the results
edhec_xts <- do.call(rbind, edhec_ytd)
edhec_years
edhec_ytd <- lapply(edhec_years, FUN = cumsum)
eq_sd <- rollapply(edhec, 3, sd)
eq_sd
# View the first three indexes of temps
index(edhec)[1:3]
indexClass(edhec)
indexTZ(edhec)
indexFormat(edhec) <- "%b-%d-%Y"
head(edhec)
indexFormat(edhec) <- "%Y-%m-%d"
times_xts <- xts(1:10, order.by = times, tzone = "America/Chicago")
tzone(edhec) <- "Asia/Hong_Kong"
edhec <- xts(1:10, order.by = times, tzone = "America/Chicago")
edhec <- xts(edhec, order.by = times, tzone = "America/Chicago")
edhec <- xts(1:10, order.by = edhec, tzone = "America/Chicago")
# Calculate the periodicity of temps
periodicity(edhec)
# Calculate the periodicity of edhec
periodicity(edhec)
# Count the months
nmonths(edhec)
# Explore underlying units of temps in two commands: .index() and .indexwday()
.index(edhec)
.indexwday(edhec)
index <- which(.indexwday(edhec) == 0 | .indexwday(edhec) == 6)
# Select the index
temps[edhec]
edhec[index]
z_unique <- make.index.unique(edhec, eps = 1e-4)
# Remove duplicate times in edhec
z_dup <- make.index.unique(edhec, drop = TRUE)
# Round observations in edhec to the next hour
z_round <- align.time(edhec, n = 3600)
a <- xts(x = 1:2, as.Date("2012-01-01") + 0:1)
a[index(a)]
b <- xts(x = 1:2, as.Date("2013-01-01") + 0:2)
b[index(b)]
b <- xts(x = 1:2, as.Date("2013-01-01") + 0:2)
b[index(b)]
b <- xts(x = 1:2, as.Date("2013-01-01") + 0:2)
b <- xts(x = 1:2, as.Date("2013-01-01") + 0:1)
b[index(b)]
a + b
a + merge(b, index(a), fill = 0)
a + merge(b, index(a), fill = na.locf)
merge(a, b, join = "inner")
merge(a, b, join = "left", fill = 0)
# Combining xts by row with rbind
# Row bind temps_june30 to temps, assign this to temps2
temps2 <- rbind(temps, temps_june30)
# Row bind temps_july17 and temps_july18 to temps2, call this temps3
temps3 <- rbind(temps2, temps_july17, temps_july18)
temps2 <- rbind(temps, temps_june30)
temps2 <- rbind(a, b)
temps_2
first(last(first(temps, "2 weeks"), "1 week"), "3 days")
edhec
xts(edhec, order.by = as.Date(rownames(edhec), "%Y/%m/%d"))
edhec <- xts(edhec, order.by = as.Date(rownames(edhec), "%Y/%m/%d"))
edhec <- xts(edhec, order.by = as.Date(rownames(edhec), "%Y/%m/%d"), na.omit = TRUE)
edhec <- readxl::read_excel("data_1.xls", sheet = 3, na.omit = TRUE)
edhec <- readxl::read_excel("data_1.xls", sheet = 3, na.rm = TRUE)
dat_zoo <- read.zoo(edhec, index.column = 0, sep = ",", format = "%Y/%m/%d")
edhec <- xts(edhec, order.by = as.Date(rownames(edhec), "%Y/%m/%d"))
remotes::install_github("ropensci/cyphr", upgrade = FALSE)
library(here)
