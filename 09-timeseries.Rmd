# Working with time-series in R

```{r load xts and zoo, message= FALSE}
# load dependencies
library(xts)
library(zoo)
```

xts objects are simple. Think of them as a matrix of observations combined with an index of corresponding dates and times. Create the object data using 5 random numbers

```{r xts objects, message= FALSE}

data <- rnorm(5)
head(data, 3)

# Create dates as a Date class object starting from 2016-01-01
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")
head(dates, 3)

# Use xts() to create data_dates
xts <- dates + data 

#xts takes two arguments: x for the data and order.by for the index
data_dates <- xts(x = data, order.by = dates)
head(data_dates, 3)

# Create one_date (1899-05-08) using a POSIXct date class object
one_date <- as.POSIXct("1899-05-08")
head(one_date, 3)

# Create some_dates and add a new attribute called one_date
some_dates <- xts(x = data, order.by = dates, born = one_date)
head(some_dates, 3)

```

Deconstructing xts
Extract the core data of some_dates
```{r deconstruct xts, message= FALSE}

some_dates_core <- coredata(some_dates)

# View the class of some_dates_core
class(some_dates_core)

# Extract the index of some_dates_core
some_dates_core_index <- index(some_dates_core)

# View the class of some_dates_core_index
class(some_dates_core_index)

# Time based indices
## Create dates
dates <- as.Date("2016-01-01") + 0:4

# Create ts_a
ts_a <- xts(x = 1:5, order.by = dates)
head(ts_a, 3)

# Create ts_b
ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))
head(ts_b, 3)

# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_b)]

# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]
```


Importing, exporting and converting time series
It is often necessary to convert between classes when working with time series data in R. 
```{r xts examples, message= FALSE}

data(sunspots)
data(austres)

# Convert austres to an xts object called au and inspect
au <- as.xts(austres)
class(au)
head(au, 3)

# Then convert your xts object (au) into a matrix am and inspect
am <- as.matrix(au)
class(am)
head(am, 3)

# Convert the original austres into a matrix am2
am2 <- as.matrix(austres)
head(am2, 3)
```

Create dat by reading tmp_file:
```{r url for xts, message= FALSE}

temp_url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
dat <- read.csv(temp_url)
head(dat)

# Convert dat into xts
xts(dat, order.by = as.Date(rownames(dat), "%m/%d/%Y"))
```

Read tmp_file using read.zoo and as.xts:

```{r read tmp file, message= FALSE}
dat_zoo <- read.zoo(temp_url, index.column = 0, sep = ",", format = "%m/%d/%Y")

# Read tmp_file using read.zoo and as.xts
dat_xts <- as.xts(dat_zoo)
head(dat_xts)

# exporting data
## Convert sunspots to xts using as.xts().
sunspots_xts <- as.xts(sunspots)

# Get the temporary file name
tmp <- tempfile()

# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = ",", file = tmp)
```

Read the tmp file. FUN = as.yearmon converts strings such as Jan 1749 into a proper time class:

```{r read zoo file, message= FALSE}
sun <- read.zoo(tmp, sep = ",", FUN = as.yearmon)
head(sun, 3)

# Convert sun into xts. Save this as sun_xts
sun_xts <- as.xts(sun)
head(sun_xts, 3)


# Select all of 2016 from x
x_2016 <- x["2010"]


# Select January 1, 2016 to March 22, 2016
jan_march <- x["2016/2016-03-22"]

# Verify that jan_march contains 82 rows
82 == length(jan_march)

# Row selection with time objects
# Subset x using the vector dates
jan_march[dates]

# Subset x using dates as POSIXct
x[as.POSIXct(dates)]

# Replace the values in x contained in the dates vector with NA
x[dates] <- NA

# Replace all values in x for dates starting June 9, 2016 with 0
x["2016-06-09/"] <- 0

# Verify that the value in x for June 11, 2016 is now indeed 0
x["2016-06-11"]

```


Additional Methods To Find Periods in Your Data
#Using the first() and last() functions

Create lastweek using the last 1 week of temps
```{r last, message= FALSE}

lastweek <- last(sun, "1 week")

# Print the last 2 observations in lastweek
last(lastweek, 2)

# Extract all but the first two days of lastweek
first(lastweek, "2 days")

# Extract the first three days of the second week of temps
first(last(first(sun, "2 weeks"), "1 week"), "3 days")
```

Math operations in xts
Matrix arithmetic - add, subtract, multiply, and divide in time!
Use coredata() or as.numeric() (drop one to a matrix or vector).
Manually shift index values - i.e. use lag().
Reindex your data (before or after the calculation).

```{r last with R, message= FALSE}

a <- xts(x = 1:2, as.Date("2012-01-01") + 0:1)
a[index(a)]


a <- xts(x = 1:2, as.Date("2012-01-01") + 0:1)
a[index(a)]

b <- xts(x = 1:2, as.Date("2013-01-01") + 0:1)
b[index(b)]


# Add a and b
a + b

# Add a with the numeric value of b
a + as.numeric(b)


# Add a to b, and fill all missing rows of b with 0
a + merge(b, index(a), fill = 0)

# Add a to b and fill NAs with the last observation
a + merge(b, index(a), fill = na.locf)

# Merging time series
## Perform an inner join of a and b
merge(a, b, join = "inner")

# Perform a left-join of a and b, fill missing values with 0
merge(a, b, join = "left", fill = 0)

# Combining xts by row with rbind
## Row bind a and b, assign this to temps2
temps2 <- rbind(a, b)
head(temps2,4)

```

Handling missingness in your data

#Airpass data: install.packages("TSA") and library(TSA)
```{r load data from TSA package, message= FALSE}
library(TSA)
data("airpass")
head(airpass, 3)
```

Fill missing values in temps using the last observation
```{r fill values of airpass, message= FALSE}
temps_last <- na.locf(airpass)
head(temps_last, 4)

```
Fill missing values in temps using the next observation
Fill missing values using last or previous observation
Last obs. carried forward: na.locf(x)                

Next obs. carried backward
na.locf(x, fromLast = TRUE)
locf = last object carried forward

```{r na.locf for airpass, message= FALSE}

temps_next <- na.locf(airpass, fromLast = TRUE)
head(temps_next, 4)

# NA interpolation using na.approx()
## Interpolate NAs using linear approximation

na.approx(airpass)
```


Lag operators and difference operations
Combine a leading and lagging time series

```{r lag airpass, message= FALSE}

# Create a lagging object called lag_x
#The k argument in zoo uses positive values for shifting past observations forward and negative values for shifting them backwards
x <- stats::lag(airpass, k = 1)
head(x, 5)
```
Merge your three series together and assign to z

Calculate a difference of a series using diff()
Calculate the first difference of AirPass using lag and subtraction

```{r diff, message= FALSE}

diff(x, differences = 2)
diff(diff(x))

diff_by_hand <- x - stats::lag(x)
head(diff_by_hand, 5)
```
Use merge to compare the first parts of diff_by_hand and diff(AirPass)
```{r diff in airpass, message= FALSE}

head(diff(airpass))

```

One of the benefits to working with time series objects is how easy it is to apply functions by time.
Apply by Time

Locate the years
```{r locate years in airpass, message= FALSE}

endpoints(airpass, on = "years")

# Locate every two years
# In order to find the end of the second year, you should set k = 2 in your second endpoints() call.
endpoints(airpass, on = "years", k = 2)

# Calculate the yearly endpoints
ep <- endpoints(airpass, on = "years")

#Using lapply() and split() to apply functions on intervals
# Split temps by years
temps_yearly <- split(airpass, f = "years") # could also split by "months" etc.

# Create a list of weekly means, temps_avg, and print this list
temps_avg <- lapply(X = temps_yearly, FUN = mean)
temps_avg

#Selection by endpoints vs. split-lapply-rbind
# Use the proper combination of split, lapply and rbind
temps_1 <- do.call(rbind, lapply(split(airpass, "years"), function(w) last(w)))
temps_1

# Create last_day_of_weeks using endpoints()
last_year_of_data <- endpoints(airpass, "years")
last_year_of_data

# Subset airpass using last_year_of_data 
temps_2 <- airpass[last_year_of_data]
temps_2
```


Convert univariate series to OHLC data
Aggregating time series
In financial series it is common to find Open-High-Low-Close data (or OHLC) calculated over some repeating and regular interval.

```{r xts data, message= FALSE}

ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))


# Convert usd_eur to weekly and assign to usd_eur_weekly
usd_eur_weekly <- to.period(x, period = "weeks")

# Convert usd_eur to monthly and assign to usd_eur_monthly
usd_eur_monthly <- to.period(x, period = "months")

# Convert eq_mkt to quarterly using shortcut function
mkt_quarterly2 <- to.monthly(x, name = "edhec_equity", indexAt = "firstof")

```


Index, Attributes, and Timezones

View the first three indexes of temps
```{r index data, message= FALSE}

index(x)[1:3]

# Get the index class of temps
indexClass(x)

# Get the timezone of temps
indexTZ(x)


# Change the time zone of times_xts to Asia/Hong_Kong
tzone(x) <- "Asia/Hong_Kong"

# Extract the current time zone of times_xts
tzone(x)
```

Periods, Periodicity and Timestamps

Calculate the periodicity of edhec

```{r periodicity of data, message= FALSE}

periodicity(x)

# Calculate the periodicity of edhec_yearly
periodicity(x)

# Count the months
nmonths(x)

# Count the quarters
nquarters(x)

```

Explore underlying units of temps in two commands: .index() and .indexwday()
.index(ts_b)
.indexwday(ts_b)

Create an index of weekend days using which():
```{r temps and index, message= FALSE}

# Make ts_b have unique timestamps
z_unique <- make.index.unique(ts_b, eps = 1e-4)
head(z_unique, 3)

# Remove duplicate times in ts_b
z_dup <- make.index.unique(ts_b, drop = TRUE)
head(z_dup, 3)

# Round observations in ts_b to the next hour
z_round <- align.time(ts_b, n = 3600)
head(z_round, 3)
```
